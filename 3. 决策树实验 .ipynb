{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b46b504c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e175d97",
   "metadata": {},
   "source": [
    "# \t3. 决策树实验\n",
    "\n",
    "## 课程目标\n",
    "1. 基于理论进一步掌握决策树学习算法。\n",
    "1. 编程实现基于信息增益、增益率和基尼指数进行划分选择的未剪枝决策树学习算法。\n",
    "\n",
    "## 课程要求\n",
    "1. 将本次课程内容写在实验报告上。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fac161",
   "metadata": {},
   "source": [
    "## 内容1\n",
    "编程实现基于信息增益进行划分选择的决策树算法，并为书中表4.2中的训练数据生成一棵决策树。\n",
    "\n",
    "提示：\n",
    "1. 树的结点可能需要定义一个类TreeNode，包含了父节点、子结点、属性选择，训练数据等有效信息；\n",
    "2. 分别定义函数计算结点的信息熵、信息增益。\n",
    "\n",
    "实验要求：\n",
    "1. 读懂下面的代码，并根据自己的理解为下面的代码写上注释；\n",
    "1. 将下面代码中的数据集DataSet读取改为从文件“3.0.csv”文件中读取；\n",
    "1. 将以下代码缺失的部分补充完成；\n",
    "4. 输出的结果如代码下一致；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3066d3a3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信息增益： 1.6157246054471703\n",
      "信息增益： 1.94570345688463\n",
      "信息增益： 2.013070929103845\n",
      "信息增益： 2.1978773673436267\n",
      "信息增益： 2.063350515708159\n",
      "信息增益： 2.2195282822995472\n",
      "信息增益： 1.1258145836939115\n",
      "信息增益： 1.6137106647166901\n",
      "信息增益： 1.4795739585136225\n",
      "信息增益： 3.125814583693911\n",
      "信息增益： 1.6341367062030678\n",
      "信息增益： 0.17095059445466854\n",
      "信息增益： 0.7709505944546686\n",
      "信息增益： 0.9709505944546686\n",
      "信息增益： 0.7709505944546686\n",
      "信息增益： 1.1709505944546685\n",
      "信息增益： 0.2516291673878229\n",
      "信息增益： 0.5849625007211563\n",
      "信息增益： 0.5849625007211563\n",
      "信息增益： 0.2516291673878229\n",
      "信息增益： 0.2516291673878229\n",
      "信息增益： 0.5849625007211563\n",
      "信息增益： 0.2516291673878229\n",
      "信息增益： 0.2516291673878229\n",
      "信息增益： 0.2516291673878229\n",
      "信息增益： 1.0\n",
      "--------------------------------------------\n",
      "current index : 1;\n",
      "data : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16];\n",
      "selected attribute is : 触感;\n",
      "children : [2, 3]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 2;\n",
      "parent index : 1;\n",
      "触感 : 硬滑;\n",
      "data : [0, 1, 2, 3, 4, 7, 8, 10, 12, 13, 15, 16];\n",
      "selected attribute is : 纹理;\n",
      "children : [4, 5, 6]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 3;\n",
      "parent index : 1;\n",
      "触感 : 软粘;\n",
      "data : [5, 6, 9, 11, 14];\n",
      "selected attribute is : 脐部;\n",
      "children : [7, 8]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 4;\n",
      "parent index : 2;\n",
      "纹理 : 清晰;\n",
      "data : [0, 1, 2, 3, 4, 7];\n",
      "label : 好瓜\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 5;\n",
      "parent index : 2;\n",
      "纹理 : 稍糊;\n",
      "data : [8, 12, 13, 16];\n",
      "label : 坏瓜\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 6;\n",
      "parent index : 2;\n",
      "纹理 : 模糊;\n",
      "data : [10, 15];\n",
      "label : 坏瓜\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 7;\n",
      "parent index : 3;\n",
      "脐部 : 稍凹;\n",
      "data : [5, 6, 14];\n",
      "selected attribute is : 根蒂;\n",
      "children : [9]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 8;\n",
      "parent index : 3;\n",
      "脐部 : 平坦;\n",
      "data : [9, 11];\n",
      "label : 坏瓜\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 9;\n",
      "parent index : 7;\n",
      "根蒂 : 稍蜷;\n",
      "data : [5, 6, 14];\n",
      "selected attribute is : 敲声;\n",
      "children : [10]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 10;\n",
      "parent index : 9;\n",
      "敲声 : 浊响;\n",
      "data : [5, 6, 14];\n",
      "selected attribute is : 色泽;\n",
      "children : [11, 12]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 11;\n",
      "parent index : 10;\n",
      "色泽 : 青绿;\n",
      "data : [5];\n",
      "label : 好瓜\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 12;\n",
      "parent index : 10;\n",
      "色泽 : 乌黑;\n",
      "data : [6, 14];\n",
      "selected attribute is : 纹理;\n",
      "children : [13, 14]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 13;\n",
      "parent index : 12;\n",
      "纹理 : 稍糊;\n",
      "data : [6];\n",
      "label : 好瓜\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 14;\n",
      "parent index : 12;\n",
      "纹理 : 清晰;\n",
      "data : [14];\n",
      "label : 坏瓜\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "# import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DataSet = [\n",
    "        # 1\n",
    "        ['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '好瓜'],\n",
    "        # 2\n",
    "        ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '好瓜'],\n",
    "        # 3\n",
    "        ['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '好瓜'],\n",
    "        # 6\n",
    "        ['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', '好瓜'],\n",
    "        # 7\n",
    "        ['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', '好瓜'],\n",
    "        # ----------------------------------------------------\n",
    "        # 10\n",
    "        ['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', '坏瓜'],\n",
    "        # 14\n",
    "        ['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', '坏瓜'],\n",
    "        # 15\n",
    "        ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', '坏瓜'],\n",
    "        # 16\n",
    "        ['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', '坏瓜'],\n",
    "        # 17\n",
    "        ['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', '坏瓜']\n",
    "    ]\n",
    "\n",
    "wm_data = pd.read_csv(r\"C:\\Users\\lenovo\\Desktop\\3.0.csv\")\n",
    "wm_data = wm_data.replace({\"好瓜\":{\"是\":'好瓜', '否':\"坏瓜\"}})\n",
    "wm_data = wm_data.drop(['编号', '含糖率', '密度'], axis=1).values\n",
    "\n",
    "\n",
    "Attributes = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感']\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    \"\"\"\n",
    "    决策树结点类\n",
    "    \"\"\"\n",
    "    current_index = 0\n",
    " \n",
    "    def __init__(self, parent=None, attr_name=None, children=None, judge=None,  data_index=None,\n",
    "                 attr_value=None, rest_attribute=None):\n",
    "        \"\"\"\n",
    "        决策树结点类初始化方法\n",
    "        :param parent: 父节点\n",
    "        \"\"\"\n",
    "        self.parent = parent  # 父节点，根节点的父节点为 None\n",
    "        self.attribute_name = attr_name  # 本节点上进行划分的属性名\n",
    "        self.attribute_value = attr_value  # 本节点上划分属性的值，是与父节点的划分属性名相对应的\n",
    "        self.children = children  # 孩子结点列表\n",
    "        self.judge = judge  # 叶子结点判断最终的分类（好瓜？坏瓜？）\n",
    "        self.data_index = data_index  # 对应训练数据集的训练索引号\n",
    "        self.index = TreeNode.current_index  # 当前结点的索引号，方便输出时查看\n",
    "        self.rest_attribute = rest_attribute  # 尚未使用的属性列表\n",
    "        TreeNode.current_index += 1\n",
    " \n",
    "    def to_string(self):\n",
    "        \"\"\"\n",
    "        用一个字符串来描述当前结点信息\n",
    "        一个普通结点的描述--------------------------------------------\n",
    "        current index : x;\n",
    "        parent index : xx;\n",
    "        parent node's attribute(父亲结点的属性划分（比方说色泽）)：青黑（此结点的色泽）\n",
    "        data：包含的训练数据\n",
    "        selected attribute(选择的属性)：xx\n",
    "        children(子节点)：x x x \n",
    "        \"\"\"\n",
    "        this_string = 'current index : ' + str(self.index) + \";\\n\"\n",
    "        if not (self.parent is None):\n",
    "            parent_node = self.parent\n",
    "            this_string = this_string + 'parent index : ' + str(parent_node.index) + \";\\n\"\n",
    "            this_string = this_string + str(parent_node.attribute_name) + \" : \" + str(self.attribute_value) + \";\\n\"\n",
    "        this_string = this_string + \"data : \" + str(self.data_index) + \";\\n\"\n",
    "        if not(self.children is None):\n",
    "            this_string = this_string + 'selected attribute is : ' + str(self.attribute_name) + \";\\n\"\n",
    "            child_list = []\n",
    "            for child in self.children:\n",
    "                child_list.append(child.index)\n",
    "            this_string = this_string + 'children : ' + str(child_list)\n",
    "        if not (self.judge is None):\n",
    "            this_string = this_string + 'label : ' + self.judge\n",
    "        return this_string\n",
    " \n",
    "\n",
    "\n",
    "    def ent(labels):\n",
    "        \"\"\"\n",
    "        样本集合的信息熵\n",
    "        :param labels: 样本集合中数据的类别标签\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        label_name = []\n",
    "        label_count = {}\n",
    "\n",
    "        for label in labels:\n",
    "            label_count[label] = label_count.get(label, 0) + 1\n",
    "            entropy = 0\n",
    "\n",
    "        for label in label_count:\n",
    "            prob = label_count[label] / len(labels)\n",
    "            entropy -= prob * math.log(prob, 2)\n",
    "        \n",
    "        \n",
    "        return entropy\n",
    "\n",
    "    def gain(attribute, labels):\n",
    "        \"\"\"\n",
    "        计算信息增益\n",
    "        :param attribute: 集合中所有样本该属性的值列表（例如青绿，乌黑，浅白）\n",
    "        :param labels: 集合中样本的数据标签\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        info_gain = TreeNode.ent(labels)\n",
    "        n = len(labels)\n",
    "        attr_count = {}\n",
    "        for i in range(len(attribute)):\n",
    "            attr = attribute[i]\n",
    "            label = labels[i]\n",
    "            attr_count[attr] = attr_count.get(attr, {})\n",
    "            attr_count[attr][label] = attr_count[attr].get(label, 0) + 1\n",
    "\n",
    "            total_entropy = TreeNode.ent(labels)\n",
    "            weighted_entropy = 0\n",
    "        for attr in attr_count:\n",
    "            attr_prob = len(attr_count[attr]) / n\n",
    "            entropy = 0\n",
    "            for label in attr_count[attr]:\n",
    "                p = attr_count[attr][label] / len(attr_count[attr])\n",
    "                entropy -= p * math.log(p, 2)\n",
    "            weighted_entropy += attr_prob * entropy\n",
    "\n",
    "            info_gain = total_entropy - weighted_entropy\n",
    "            \n",
    "        print('信息增益：', info_gain)\n",
    "        return info_gain\n",
    "\n",
    "\n",
    "\n",
    "    def finish_node(current_node, data, label):\n",
    "        \"\"\"\n",
    "        完成当前结点的后续计算，包括选择属性，划分子节点等\n",
    "        :param current_node: 当前的结点\n",
    "        :param data: 数据集\n",
    "        :param label: 数据集的 label\n",
    "        :param rest_title: 剩余的可用属性名\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # n = len(label)\n",
    "\n",
    "        # 1.判断当前结点的数据是否属于同一类，如果是，直接标记为叶子结点并返回\n",
    "        one_class = True\n",
    "\n",
    "        this_data_index = current_node.data_index #训练数据在训练集中的索引序号\n",
    "\n",
    "        for i in this_data_index:\n",
    "            for j in this_data_index:\n",
    "                if label[i] != label[j]:\n",
    "                    one_class = False\n",
    "                    break\n",
    "            if not one_class:\n",
    "                break\n",
    "        if one_class:\n",
    "            current_node.judge = label[this_data_index[0]]\n",
    "            return\n",
    "\n",
    "        # 2. 如果当前结点的数据不是同一类，但候选属性为空\n",
    "        rest_title = current_node.rest_attribute  # 候选属性\n",
    "        if len(rest_title) == 0:  # 如果候选属性为空，则是个叶子结点。需要选择最多的那个类作为该结点的类\n",
    "            label_count = {}\n",
    "            temp_data = current_node.data_index \n",
    "            for index in temp_data:\n",
    "                if label_count.__contains__(label[index]):\n",
    "                    label_count[label[index]] += 1\n",
    "                else:\n",
    "                    label_count[label[index]] = 1\n",
    "            final_label = max(label_count)\n",
    "            current_node.judge = final_label\n",
    "            return\n",
    "\n",
    "        # 3. 如果剩余有多个属性\n",
    "        title_gain = {}  # 记录每个属性的信息增益\n",
    "        for title in rest_title: #挑选属性\n",
    "            attr_values = []\n",
    "            current_label = []\n",
    "            for index in current_node.data_index:\n",
    "                this_data = data[index]\n",
    "                attr_values.append(this_data[title]) # 记录此样本的属性值，直至结点所有样本的属性都记录\n",
    "                current_label.append(label[index])   # 记录此样本的标签，直至结点所有样本的标签都记录\n",
    "            temp_data = data[0] # temp_data中是第一个样本数据包含特征属性\n",
    "            this_gain = TreeNode.gain(attr_values, current_label)  \n",
    "            title_gain[title] = this_gain\n",
    "\n",
    "        best_attr = max(title_gain, key=title_gain.get)  # 信息增益最大的属性名\n",
    "        current_node.attribute_name = best_attr\n",
    "        rest_title.remove(best_attr)\n",
    "\n",
    "        # a_data = data[0] # 记录第一个数据的特征属性有什么\n",
    "\n",
    "        # 属性划分\n",
    "        best_titlevalue_dict = {}  # key是属性值的取值，value是个list记录所包含的样本序号\n",
    "        for index in current_node.data_index:\n",
    "            this_data = data[index] #取出该序号下的数据 --\n",
    "            if best_titlevalue_dict.__contains__(this_data[best_attr]):\n",
    "                temp_list = best_titlevalue_dict[this_data[best_attr]]\n",
    "                temp_list.append(index)\n",
    "            else:                                 #新属性值出现\n",
    "                temp_list = [index]\n",
    "                best_titlevalue_dict[this_data[best_attr]] = temp_list\n",
    "\n",
    "        children_list = []\n",
    "        for key, index_list in best_titlevalue_dict.items():\n",
    "            a_child = TreeNode(parent=current_node, data_index=index_list, attr_value=key, rest_attribute=rest_title.copy())\n",
    "            children_list.append(a_child)\n",
    "        current_node.children = children_list\n",
    "\n",
    "        # print(current_node.to_string())\n",
    "        for child in current_node.children:  # 递归\n",
    "            TreeNode.finish_node(child, data, label)\n",
    "            \n",
    "        \n",
    "def id3_tree(Data, title, label):\n",
    "    \"\"\"\n",
    "    id3方法构造决策树，使用的标准是信息增益（信息熵）\n",
    "    :param Data: 数据集，每个样本是一个 dict(属性名：属性值)，整个 Data 是个大的 list\n",
    "    :param title: 每个属性的名字，如 色泽、根蒂等\n",
    "    :param label: 存储的是每个样本的类别\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n = len(Data)\n",
    "    root_data = []\n",
    "    for i in range(0, n):\n",
    "        root_data.append(i)\n",
    "        \n",
    "    root_node = TreeNode(data_index=root_data, rest_attribute=title.copy())\n",
    "    TreeNode.finish_node(root_node, Data, label)\n",
    "    \n",
    "    return root_node\n",
    " \n",
    "    \n",
    "def print_tree(root=TreeNode()):\n",
    "    \"\"\"\n",
    "    打印输出一颗树\n",
    "    :param root: 根节点\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    node_list = [root]\n",
    "    while(len(node_list)>0):\n",
    "        current_node = node_list[0]\n",
    "        print('--------------------------------------------')\n",
    "        print(current_node.to_string())\n",
    "        print('--------------------------------------------')\n",
    "        children_list = current_node.children\n",
    "        if not (children_list is None):\n",
    "            for child in children_list:\n",
    "                node_list.append(child)\n",
    "        node_list.remove(current_node)\n",
    "        \n",
    "        \n",
    "        \n",
    "data = []  # 存放数据\n",
    "label = []  # 存放标签\n",
    "for sample in wm_data:\n",
    "    a_dict = {}\n",
    "    dim = len(sample) - 1\n",
    "    for i in range(0, dim):\n",
    "        a_dict[Attributes[i]] = sample[i]\n",
    "    data.append(a_dict)\n",
    "    label.append(sample[dim])\n",
    "    \n",
    " \n",
    "\n",
    "decision_tree = id3_tree(data, Attributes, label)\n",
    "print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb7af56",
   "metadata": {},
   "source": [
    "## 内容2\n",
    "\n",
    "结合搜索引擎阅读并理解以下代码。\n",
    "\n",
    "并回答：以下代码和课上所授决策树内容有什么区别？\n",
    "\n",
    "**注意，请将以下代码中random_state替换为自己学号的后五位。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551187fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the decision tree is: 0.9333333333333333\n",
      "{'type': 'internal', 'feature': 'petal length (cm)', 'threshold': 1.9, 'left': {'type': 'leaf', 'class': 0}, 'right': {'type': 'internal', 'feature': 'petal width (cm)', 'threshold': 1.6, 'left': {'type': 'internal', 'feature': 'petal length (cm)', 'threshold': 4.9, 'left': {'type': 'leaf', 'class': 1}, 'right': {'type': 'leaf', 'class': 2}}, 'right': {'type': 'leaf', 'class': 2}}}\n"
     ]
    }
   ],
   "source": [
    "%reset -f\n",
    "# 导入所需的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 加载鸢尾花数据集\n",
    "iris = load_iris()\n",
    "X = iris.data # 特征矩阵\n",
    "y = iris.target # 类别向量\n",
    "feature_names = iris.feature_names # 特征名称\n",
    "\n",
    "# 划分训练集和测试集\n",
    "random_state = 60090\n",
    "np.random.seed(random_state) # 设置随机种子，保证可复现性\n",
    "indices = np.random.permutation(len(X)) # 生成随机索引   # np.random.permutation生成随机排序序列,多维数据的话，只是对第一维进行了操作\n",
    "split = int(len(X) * 0.8) # 设置划分比例为80%\n",
    "X_train = X[indices[:split]] # 训练集特征\n",
    "y_train = y[indices[:split]] # 训练集类别\n",
    "X_test = X[indices[split:]] # 测试集特征\n",
    "y_test = y[indices[split:]] # 测试集类别\n",
    "\n",
    "# 定义计算基尼指数的函数\n",
    "def gini(y):\n",
    "    \"\"\"\n",
    "    输入：类别向量y\n",
    "    输出：基尼指数\n",
    "    \"\"\"\n",
    "    # np.unique是去重，并按从小到大的顺序输出列表元素；return_counts=True,返回去重数组元素出现的次数；得到freqs即每个类别的频率，表示为所有类比构成的一个数组\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    freqs = counts / len(y)  \n",
    "    # 根据基尼公式--由于freqs存储当前节点处每个待分类属性的频率，使用np.sum求出在该样本中的抽取两个数，类别不一样的概率\n",
    "    gini = 1 - np.sum(freqs**2)\n",
    "    return gini\n",
    "\n",
    "# 定义根据特征和阈值划分数据集的函数\n",
    "def split_dataset(X, y, feature_index, threshold):\n",
    "    \"\"\"\n",
    "    输入：特征矩阵X，类别向量y，特征索引feature_index，阈值threshold\n",
    "    输出：划分后的左右子集(X_left, y_left), (X_right, y_right)\n",
    "    \"\"\"\n",
    "    # 根据特征和阈值对数据进行二分划分\n",
    "    left_indices = X[:, feature_index] <= threshold # 左子集的索引\n",
    "    right_indices = X[:, feature_index] > threshold # 右子集的索引\n",
    "    X_left = X[left_indices] # 左子集特征\n",
    "    y_left = y[left_indices] # 左子集类别\n",
    "    X_right = X[right_indices] # 右子集特征\n",
    "    y_right = y[right_indices] # 右子集类别\n",
    "    return (X_left, y_left), (X_right, y_right)\n",
    "\n",
    "# 定义寻找最佳划分特征和阈值的函数\n",
    "def best_split(X, y):\n",
    "    \"\"\"\n",
    "    输入：特征矩阵X，类别向量y\n",
    "    输出：最佳划分特征best_feature，最佳划分阈值best_threshold，最佳划分基尼指数best_gini\n",
    "    \"\"\"\n",
    "    # 初始化最佳划分参数\n",
    "    best_feature = None \n",
    "    best_threshold = None \n",
    "    best_gini = 1 # 最大可能的基尼指数为1\n",
    "    \n",
    "    n_features = X.shape[1] # 特征的数量\n",
    "    \n",
    "    for feature_index in range(n_features): # 遍历每个特征\n",
    "        feature_values = X[:, feature_index] # 获取该特征的所有取值\n",
    "        possible_thresholds = np.unique(feature_values) # 获取该特征的所有可能的阈值\n",
    "        \n",
    "        for threshold in possible_thresholds: # 遍历每个阈值\n",
    "            # 根据该特征和阈值划分数据集为左右两个子集\n",
    "            (X_left, y_left), (X_right, y_right) = split_dataset(X, y, feature_index, threshold)\n",
    "            if len(y_left) == 0 or len(y_right) == 0: # 如果某个子集为空，则跳过该划分\n",
    "                continue\n",
    "            # 计算左右子集的权重和基尼指数\n",
    "            weight_left = len(y_left) / len(y)\n",
    "            weight_right = len(y_right) / len(y)\n",
    "            gini_left = gini(y_left)\n",
    "            gini_right = gini(y_right)\n",
    "            # 计算该划分的加权基尼指数\n",
    "            weighted_gini = weight_left * gini_left + weight_right * gini_right\n",
    "            # 如果该划分的基尼指数小于当前最佳划分的基尼指数，则更新最佳划分参数\n",
    "            if weighted_gini < best_gini:\n",
    "                best_feature = feature_index\n",
    "                best_threshold = threshold\n",
    "                best_gini = weighted_gini\n",
    "    \n",
    "    return best_feature, best_threshold, best_gini\n",
    "\n",
    "\n",
    "# 定义构建决策树的函数\n",
    "def build_tree(X, y, max_depth=5, min_samples_split=2):\n",
    "    \"\"\"\n",
    "    输入：特征矩阵X，类别向量y，最大深度max_depth，最小划分样本数min_samples_split\n",
    "    输出：决策树，以字典的形式表示\n",
    "    \"\"\"\n",
    "    # 创建一个空字典，用于存储决策树的信息\n",
    "    tree = {}\n",
    "    \n",
    "    # 如果节点中的数据属于同一类别，则将节点标记为叶子节点，并返回其类别标签\n",
    "    if len(np.unique(y)) == 1:\n",
    "        tree[\"type\"] = \"leaf\"\n",
    "        tree[\"class\"] = y[0]\n",
    "        return tree\n",
    "    \n",
    "    # 如果节点的深度达到了最大深度，则将节点标记为叶子节点，并返回其数据中出现最多的类别标签\n",
    "    if max_depth == 0:\n",
    "        tree[\"type\"] = \"leaf\"\n",
    "        tree[\"class\"] = np.bincount(y).argmax()\n",
    "        return tree\n",
    "    \n",
    "    # 如果节点的数据量小于最小划分样本数，则将节点标记为叶子节点，并返回其数据中出现最多的类别标签\n",
    "    if len(y) < min_samples_split:\n",
    "        tree[\"type\"] = \"leaf\"\n",
    "        tree[\"class\"] = np.bincount(y).argmax()\n",
    "        return tree\n",
    "    \n",
    "    # 否则，寻找最佳划分特征和阈值，并将节点分为左右两个子节点\n",
    "    best_feature, best_threshold, best_gini = best_split(X, y)\n",
    "    \n",
    "    # 如果没有找到合适的划分，则将节点标记为叶子节点，并返回其数据中出现最多的类别标签\n",
    "    if best_feature is None or best_threshold is None:\n",
    "        tree[\"type\"] = \"leaf\"\n",
    "        tree[\"class\"] = np.bincount(y).argmax()\n",
    "        return tree\n",
    "    \n",
    "    # 否则，根据最佳划分特征和阈值划分数据集为左右两个子集\n",
    "    (X_left, y_left), (X_right, y_right) = split_dataset(X, y, best_feature, best_threshold)\n",
    "    \n",
    "    # 将节点标记为内部节点，并存储其划分特征和阈值\n",
    "    tree[\"type\"] = \"internal\"\n",
    "    tree[\"feature\"] = feature_names[best_feature]\n",
    "    tree[\"threshold\"] = best_threshold\n",
    "    \n",
    "    # 递归地对左右子节点进行同样的操作，减少最大深度\n",
    "    tree[\"left\"] = build_tree(X_left, y_left, max_depth-1, min_samples_split)\n",
    "    tree[\"right\"] = build_tree(X_right, y_right, max_depth-1, min_samples_split)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "\n",
    "# 定义根据决策树对新数据进行预测的函数\n",
    "def predict(tree, x):\n",
    "    \"\"\"\n",
    "    输入：决策树tree，单个样本x（一维数组）\n",
    "    输出：预测结果y_pred（整数）\n",
    "    \"\"\"\n",
    "    \n",
    "    # 如果当前节点是叶子节点，则返回其类别标签作为预测结果\n",
    "    if tree[\"type\"] == \"leaf\":\n",
    "        return tree[\"class\"]\n",
    "    \n",
    "    # 否则，根据当前节点的划分特征和阈值将样本分配到左右子节点中\n",
    "    feature_index = feature_names.index(tree[\"feature\"]) # 获取划分特征的索引\n",
    "    threshold = tree[\"threshold\"] # 获取划分阈值\n",
    "    \n",
    "    if x[feature_index] <= threshold: # 如果样本的特征值小于等于阈值，则分配到左子节点\n",
    "        return predict(tree[\"left\"], x)\n",
    "    else: # 否则，分配到右子节点\n",
    "        return predict(tree[\"right\"], x)\n",
    "\n",
    "# 使用训练数据集构建决策树\n",
    "tree = build_tree(X_train, y_train, max_depth=3, min_samples_split=5)\n",
    "\n",
    "# 使用测试数据集进行预测，并计算准确率\n",
    "y_pred = [predict(tree, x) for x in X_test]\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"The accuracy of the decision tree is:\", accuracy)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4c29325-fae0-4231-b3a0-b3a4aa56d65f",
   "metadata": {},
   "source": [
    "## 内容3 在理解内容1和2的基础上，不借助sklearn编写程序，编程实现基于增益率和基尼指数进行划分选择的决策树算法，并为书中表4.2中的训练数据生成一棵决策树。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7869c45b-70b9-4fb4-9c7f-26b58bddb79e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'色泽': 0.4982698961937716, '根蒂': 0.4982698961937716, '敲声': 0.4982698961937716, '纹理': 0.4982698961937716, '脐部': 0.4982698961937716, '触感': 0.4982698961937716, '含糖率': 0.06696192680347068, '密度': 0.06696192680347068}\n",
      "{'根蒂': 0.5, '敲声': 0.5, '纹理': 0.5, '脐部': 0.5, '触感': 0.5, '含糖率': 0.19087450462110944, '密度': 0.19087450462110944}\n",
      "{'敲声': 0.4444444444444444, '纹理': 0.4444444444444444, '脐部': 0.4444444444444444, '触感': 0.4444444444444444, '含糖率': 0.9182958340544896, '密度': 0.2516291673878229}\n",
      "{'敲声': 0.5, '纹理': 0.5, '脐部': 0.5, '触感': 0.5, '含糖率': 1.0, '密度': 1.0}\n",
      "{'根蒂': 0.4444444444444444, '敲声': 0.4444444444444444, '纹理': 0.4444444444444444, '脐部': 0.4444444444444444, '触感': 0.4444444444444444, '含糖率': 0.109170338675599, '密度': 0.109170338675599}\n",
      "{'敲声': 0.5, '纹理': 0.5, '脐部': 0.5, '触感': 0.5, '含糖率': 0.31127812445913283, '密度': 0.31127812445913283}\n",
      "{'纹理': 0.4444444444444444, '脐部': 0.4444444444444444, '触感': 0.4444444444444444, '含糖率': 0.2516291673878229, '密度': 0.9182958340544896}\n",
      "{'根蒂': 0.31999999999999984, '敲声': 0.31999999999999984, '纹理': 0.31999999999999984, '脐部': 0.31999999999999984, '触感': 0.31999999999999984, '含糖率': 0.07290559532005603, '密度': 0.7219280948873623}\n",
      "--------------------------------------------\n",
      "current index : 1;\n",
      "data : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16];\n",
      "selected attribute is : 色泽;\n",
      "children : [2, 3, 4]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 2;\n",
      "parent index : 1;\n",
      "色泽 : 青绿;\n",
      "data : [0, 3, 5, 9, 12, 16];\n",
      "selected attribute is : 根蒂;\n",
      "children : [5, 6, 7]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 3;\n",
      "parent index : 1;\n",
      "色泽 : 乌黑;\n",
      "data : [1, 2, 6, 7, 8, 14];\n",
      "selected attribute is : 根蒂;\n",
      "children : [13, 14]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 4;\n",
      "parent index : 1;\n",
      "色泽 : 浅白;\n",
      "data : [4, 10, 11, 13, 15];\n",
      "selected attribute is : 密度;\n",
      "children : [20, 21, 22, 23, 24]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 5;\n",
      "parent index : 2;\n",
      "根蒂 : 蜷缩;\n",
      "data : [0, 3, 16];\n",
      "selected attribute is : 含糖率;\n",
      "children : [8, 9, 10]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 6;\n",
      "parent index : 2;\n",
      "根蒂 : 稍蜷;\n",
      "data : [5, 12];\n",
      "selected attribute is : 含糖率;\n",
      "children : [11, 12]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 7;\n",
      "parent index : 2;\n",
      "根蒂 : 硬挺;\n",
      "data : [9];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 13;\n",
      "parent index : 3;\n",
      "根蒂 : 蜷缩;\n",
      "data : [1, 2];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 14;\n",
      "parent index : 3;\n",
      "根蒂 : 稍蜷;\n",
      "data : [6, 7, 8, 14];\n",
      "selected attribute is : 敲声;\n",
      "children : [15, 16]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 20;\n",
      "parent index : 4;\n",
      "密度 : 0.215;\n",
      "data : [4];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 21;\n",
      "parent index : 4;\n",
      "密度 : 0.057;\n",
      "data : [10];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 22;\n",
      "parent index : 4;\n",
      "密度 : 0.099;\n",
      "data : [11];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 23;\n",
      "parent index : 4;\n",
      "密度 : 0.198;\n",
      "data : [13];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 24;\n",
      "parent index : 4;\n",
      "密度 : 0.042;\n",
      "data : [15];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 8;\n",
      "parent index : 5;\n",
      "含糖率 : 0.697;\n",
      "data : [0];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 9;\n",
      "parent index : 5;\n",
      "含糖率 : 0.608;\n",
      "data : [3];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 10;\n",
      "parent index : 5;\n",
      "含糖率 : 0.719;\n",
      "data : [16];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 11;\n",
      "parent index : 6;\n",
      "含糖率 : 0.403;\n",
      "data : [5];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 12;\n",
      "parent index : 6;\n",
      "含糖率 : 0.639;\n",
      "data : [12];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 15;\n",
      "parent index : 14;\n",
      "敲声 : 浊响;\n",
      "data : [6, 7, 14];\n",
      "selected attribute is : 密度;\n",
      "children : [17, 18, 19]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 16;\n",
      "parent index : 14;\n",
      "敲声 : 沉闷;\n",
      "data : [8];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 17;\n",
      "parent index : 15;\n",
      "密度 : 0.149;\n",
      "data : [6];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 18;\n",
      "parent index : 15;\n",
      "密度 : 0.211;\n",
      "data : [7];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 19;\n",
      "parent index : 15;\n",
      "密度 : 0.37;\n",
      "data : [14];\n",
      "label : 否\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 此处完成内容3的代码实现\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wm_data = pd.read_csv(r\"C:\\Users\\lenovo\\Desktop\\3.0.csv\")\n",
    "wm_data = wm_data.drop(['编号'], axis=1).values\n",
    "\n",
    "\n",
    "\n",
    "Attributes = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '含糖率', '密度']\n",
    "\n",
    "\n",
    "def Gini(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    freqs = counts / len(y)\n",
    "    \n",
    "    gini = 1 - np.sum(freqs**2)\n",
    "    \n",
    "    return gini\n",
    "\n",
    "\n",
    "def split_selection(attribute, y, split_type):\n",
    "    if split_type == 1:\n",
    "        return Gini(y)\n",
    "    \n",
    "    if split_type == 2:\n",
    "        return gain(attribute, y)\n",
    "        \n",
    "    if split_type == 3:\n",
    "        return gain_rate(attribute, y)\n",
    "    \n",
    "    \n",
    "def Ent(labels):\n",
    "    label_name = []\n",
    "    label_count = {}\n",
    "\n",
    "    for label in labels:\n",
    "        label_count[label] = label_count.get(label, 0) + 1\n",
    "        entropy = 0\n",
    "\n",
    "    for label in label_count:\n",
    "        prob = label_count[label] / len(labels)\n",
    "        entropy -= prob * np.log2(prob)\n",
    "    \n",
    "\n",
    "    return entropy\n",
    "\n",
    "def gain(attribute, labels):\n",
    "    info_gain = Ent(labels)\n",
    "    s = set(attribute)\n",
    "    gain = 0\n",
    "    atr_index = list(enumerate(attribute))\n",
    "    \n",
    "    \n",
    "    for atr in s:\n",
    "        p_atr = attribute.count(atr) / len(attribute)\n",
    "        label_atr = []\n",
    "        for j in range(len(labels)):\n",
    "            if atr_index[j][1] == atr:\n",
    "                label_atr.append(labels[j])\n",
    "                \n",
    "        ent_atr = Ent(label_atr)\n",
    "        gain += p_atr*ent_atr\n",
    "    \n",
    "\n",
    "    return info_gain - gain\n",
    "\n",
    "def gain_rate(attribute, labels):\n",
    "    info_gain = Ent(labels)\n",
    "    s = set(attribute)\n",
    "    gain = 0\n",
    "    IV_atr = 0\n",
    "    atr_index = list(enumerate(attribute))\n",
    "    \n",
    "    \n",
    "    for atr in s:\n",
    "        p_atr = attribute.counts(atr) / len(attribute)\n",
    "        label_atr = []\n",
    "        for j in range(len(labels)):\n",
    "            if atr_index[j][1] == atr:\n",
    "                label_atr.append(labels[j])\n",
    "                \n",
    "        ent_atr = Ent(label_atr)\n",
    "        gain += p_atr*ent_atr\n",
    "        IV_atr += p_atr*np.log2(p_atr)\n",
    "    \n",
    "    gain_ratio = (info_gain - gain) / IV_atr\n",
    "    \n",
    "    return gain_ratio\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class TreeNode:\n",
    "    current_index = 0\n",
    "    def __init__(self, parent=None, attr_name=None, children=None, judge=None,  data_index=None,\n",
    "                 attr_value=None, rest_attribute=None):\n",
    "        \"\"\"\n",
    "        决策树结点类初始化方法\n",
    "        :param parent: 父节点\n",
    "        \"\"\"\n",
    "        self.parent = parent  \n",
    "        self.attribute_name = attr_name \n",
    "        self.attribute_value = attr_value  \n",
    "        self.children = children \n",
    "        self.judge = judge  \n",
    "        self.data_index = data_index  \n",
    "        self.index = TreeNode.current_index  \n",
    "        self.rest_attribute = rest_attribute  \n",
    "        TreeNode.current_index += 1\n",
    " \n",
    "    def to_string(self):\n",
    "        \"\"\"\n",
    "        用一个字符串来描述当前结点信息\n",
    "        一个普通结点的描述--------------------------------------------\n",
    "        current index : x;\n",
    "        parent index : xx;\n",
    "        parent node's attribute(父亲结点的属性划分（比方说色泽）)：青黑（此结点的色泽）\n",
    "        data：包含的训练数据\n",
    "        selected attribute(选择的属性)：xx\n",
    "        children(子节点)：x x x \n",
    "        \"\"\"\n",
    "        this_string = 'current index : ' + str(self.index) + \";\\n\"\n",
    "        if not (self.parent is None):\n",
    "            parent_node = self.parent\n",
    "            this_string = this_string + 'parent index : ' + str(parent_node.index) + \";\\n\"\n",
    "            this_string = this_string + str(parent_node.attribute_name) + \" : \" + str(self.attribute_value) + \";\\n\"\n",
    "        this_string = this_string + \"data : \" + str(self.data_index) + \";\\n\"\n",
    "        if not(self.children is None):\n",
    "            this_string = this_string + 'selected attribute is : ' + str(self.attribute_name) + \";\\n\"\n",
    "            child_list = []\n",
    "            for child in self.children:\n",
    "                child_list.append(child.index)\n",
    "            this_string = this_string + 'children : ' + str(child_list)\n",
    "        if not (self.judge is None):\n",
    "            this_string = this_string + 'label : ' + self.judge\n",
    "        return this_string\n",
    "    \n",
    "    \n",
    "\n",
    "def finish_node(current_node, X, label, split_type):\n",
    "    one_class = True\n",
    " \n",
    "    this_data_index = current_node.data_index\n",
    "    for i in this_data_index:\n",
    "        for j in this_data_index:\n",
    "            if label[i] != label[j]:\n",
    "                one_class = False\n",
    "                break\n",
    "        if not one_class:\n",
    "            break\n",
    "    if one_class:\n",
    "        \n",
    "        current_node.judge = label[this_data_index[0]]\n",
    "        return\n",
    "    \n",
    "    rest_title = current_node.rest_attribute \n",
    "    if len(rest_title) == 0: \n",
    "        label_count = {}\n",
    "        temp_data = current_node.data_index \n",
    "        for index in temp_data:\n",
    "            if label[index] in label_count:\n",
    "                label_count[label[index]] += 1\n",
    "            else:\n",
    "                label_count[label[index]] = 1\n",
    "        final_label = max(label_count)\n",
    "        current_node.judge = final_label\n",
    "        return\n",
    "    \n",
    "    \n",
    "    attribute_eva = {}  # 记录每个属性的评价(1.信息增益 2.增益率 3.基尼指数)\n",
    "    for attr in rest_title: #挑选属性\n",
    "        attr_values = []\n",
    "        current_label = []\n",
    "        for index in current_node.data_index:\n",
    "            this_data = X[index]\n",
    "            attr_values.append(this_data[attr]) \n",
    "            current_label.append(label[index])   \n",
    "        \n",
    "        \n",
    "        if attr not in ['密度', '含糖率']:\n",
    "            this_gain = split_selection(attr_values, current_label, split_type)  \n",
    "            attribute_eva[attr] = this_gain\n",
    "        else:\n",
    "            x_feature = sorted(set(attr_values)) \n",
    "            feature_values = []\n",
    "            for i in range(len(x_feature) - 1):  # 计算划分点\n",
    "                feature_values.append((float(x_feature[i]) + float(\n",
    "                    x_feature[i + 1])) / 2)\n",
    "\n",
    "            \n",
    "            for threshold in feature_values:\n",
    "                attr_left = []\n",
    "                label_left = []\n",
    "                label_right = []\n",
    "                attr_right = []\n",
    "                min_entropy = 100\n",
    "                best_threshold = 0\n",
    "                for i in range(len(attr_values)):\n",
    "                    if attr_values[i] < threshold:\n",
    "                        attr_left.append(attr_values[i])\n",
    "                        label_left.append(current_label[i])\n",
    "                    else:\n",
    "                        attr_right.append(attr_values[i])\n",
    "                        label_right.append(current_label[i])\n",
    "                \n",
    "                prob_left = len(attr_left) / len(attr_values)\n",
    "                prob_right = len(attr_right) / len(attr_values)\n",
    "                entropy = prob_left * Ent(label_left) + prob_right * Ent(label_right)\n",
    "                \n",
    "                if entropy < min_entropy:\n",
    "                    min_entropy = entropy\n",
    "                    best_threshold = threshold\n",
    "                    \n",
    "            this_gain = Ent(current_label) - min_entropy\n",
    "            attribute_eva[attr] = this_gain\n",
    "                \n",
    "    print(attribute_eva)\n",
    "    best_attr = max(attribute_eva, key=attribute_eva.get)  \n",
    "    current_node.attribute_name = best_attr\n",
    "    rest_title.remove(best_attr)\n",
    " \n",
    "    \n",
    "\n",
    "    # 属性划分\n",
    "    best_titlevalue_dict = {}  # key是属性值的取值，value是个list记录所包含的样本序号\n",
    "    for index in current_node.data_index:\n",
    "        this_data = X[index] \n",
    "        if this_data[best_attr] in best_titlevalue_dict:\n",
    "            temp_list = best_titlevalue_dict[this_data[best_attr]]\n",
    "            temp_list.append(index)\n",
    "        else:                                \n",
    "            temp_list = [index]\n",
    "            best_titlevalue_dict[this_data[best_attr]] = temp_list\n",
    " \n",
    "    children_list = []\n",
    "    for key, index_list in best_titlevalue_dict.items():\n",
    "        a_child = TreeNode(parent=current_node, data_index=index_list, attr_value=key, rest_attribute=rest_title.copy())\n",
    "        children_list.append(a_child)\n",
    "    current_node.children = children_list\n",
    " \n",
    "   \n",
    "    for child in current_node.children:  \n",
    "        finish_node(child, X, label, split_type)\n",
    "\n",
    "def id3_tree(X, title, label, split_type):\n",
    "    n = len(X)\n",
    "    root_data = []\n",
    "    for i in range(0, n):\n",
    "        root_data.append(i)\n",
    "        \n",
    "    root_node = TreeNode(data_index=root_data, rest_attribute=title.copy())\n",
    "    finish_node(root_node, X, label, split_type)\n",
    "    \n",
    "    return root_node\n",
    " \n",
    "    \n",
    "def print_tree(root=TreeNode()):\n",
    "    \"\"\"\n",
    "    打印输出一颗树\n",
    "    :param root: 根节点\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    node_list = [root]\n",
    "    while(len(node_list)>0):\n",
    "        current_node = node_list[0]\n",
    "        print('--------------------------------------------')\n",
    "        print(current_node.to_string())\n",
    "        print('--------------------------------------------')\n",
    "        children_list = current_node.children\n",
    "        if not (children_list is None):\n",
    "            for child in children_list:\n",
    "                node_list.append(child)\n",
    "        node_list.remove(current_node)\n",
    "        \n",
    "        \n",
    "        \n",
    "data = [] \n",
    "label = []  \n",
    "for sample in wm_data:\n",
    "    a_dict = {}\n",
    "    dim = len(sample) - 1\n",
    "    for i in range(0, dim):\n",
    "        a_dict[Attributes[i]] = sample[i]\n",
    "    data.append(a_dict)\n",
    "    label.append(sample[dim])\n",
    "\n",
    "decision_tree = id3_tree(data, Attributes, label, 1)\n",
    "print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c08955b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'色泽': 0.10812516526536531, '根蒂': 0.14267495956679288, '敲声': 0.14078143361499584, '纹理': 0.3805918973682686, '脐部': 0.28915878284167895, '触感': 0.006046489176565584, '含糖率': 0.06696192680347068, '密度': 0.06696192680347068}\n",
      "{'色泽': 0.04306839587828004, '根蒂': 0.45810589515712374, '敲声': 0.33085622540971754, '脐部': 0.45810589515712374, '触感': 0.45810589515712374, '含糖率': 0.04306839587828004, '密度': 0.04306839587828004}\n",
      "{'色泽': 0.2516291673878229, '敲声': 0.0, '脐部': 0.0, '触感': 0.2516291673878229, '含糖率': 0.2516291673878229, '密度': 0.9182958340544896}\n",
      "{'色泽': 0.3219280948873623, '根蒂': 0.07290559532005603, '敲声': 0.3219280948873623, '脐部': 0.17095059445466865, '触感': 0.7219280948873623, '含糖率': 0.07290559532005603, '密度': 0.07290559532005603}\n",
      "--------------------------------------------\n",
      "current index : 1;\n",
      "data : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16];\n",
      "selected attribute is : 纹理;\n",
      "children : [2, 3, 4]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 2;\n",
      "parent index : 1;\n",
      "纹理 : 清晰;\n",
      "data : [0, 1, 2, 3, 4, 5, 7, 9, 14];\n",
      "selected attribute is : 根蒂;\n",
      "children : [5, 6, 7]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 3;\n",
      "parent index : 1;\n",
      "纹理 : 稍糊;\n",
      "data : [6, 8, 12, 13, 16];\n",
      "selected attribute is : 触感;\n",
      "children : [11, 12]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 4;\n",
      "parent index : 1;\n",
      "纹理 : 模糊;\n",
      "data : [10, 11, 15];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 5;\n",
      "parent index : 2;\n",
      "根蒂 : 蜷缩;\n",
      "data : [0, 1, 2, 3, 4];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 6;\n",
      "parent index : 2;\n",
      "根蒂 : 稍蜷;\n",
      "data : [5, 7, 14];\n",
      "selected attribute is : 密度;\n",
      "children : [8, 9, 10]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 7;\n",
      "parent index : 2;\n",
      "根蒂 : 硬挺;\n",
      "data : [9];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 11;\n",
      "parent index : 3;\n",
      "触感 : 软粘;\n",
      "data : [6];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 12;\n",
      "parent index : 3;\n",
      "触感 : 硬滑;\n",
      "data : [8, 12, 13, 16];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 8;\n",
      "parent index : 6;\n",
      "密度 : 0.237;\n",
      "data : [5];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 9;\n",
      "parent index : 6;\n",
      "密度 : 0.211;\n",
      "data : [7];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 10;\n",
      "parent index : 6;\n",
      "密度 : 0.37;\n",
      "data : [14];\n",
      "label : 否\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wm_data = pd.read_csv(r\"C:\\Users\\lenovo\\Desktop\\3.0.csv\")\n",
    "wm_data = wm_data.drop(['编号'], axis=1).values\n",
    "\n",
    "\n",
    "\n",
    "Attributes = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '含糖率', '密度']\n",
    "\n",
    "\n",
    "def Gini(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    freqs = counts / len(y)\n",
    "    \n",
    "    gini = 1 - np.sum(freqs**2)\n",
    "    \n",
    "    return gini\n",
    "\n",
    "\n",
    "def split_selection(attribute, y, split_type):\n",
    "    if split_type == 1:\n",
    "        return Gini(y)\n",
    "    \n",
    "    if split_type == 2:\n",
    "        return gain(attribute, y)\n",
    "        \n",
    "    if split_type == 3:\n",
    "        return gain_rate(attribute, y)\n",
    "    \n",
    "    \n",
    "def Ent(labels):\n",
    "    label_name = []\n",
    "    label_count = {}\n",
    "\n",
    "    for label in labels:\n",
    "        label_count[label] = label_count.get(label, 0) + 1\n",
    "        entropy = 0\n",
    "\n",
    "    for label in label_count:\n",
    "        prob = label_count[label] / len(labels)\n",
    "        entropy -= prob * np.log2(prob)\n",
    "        \n",
    "    return entropy\n",
    "\n",
    "def gain(attribute, labels):\n",
    "    info_gain = Ent(labels)\n",
    "    s = set(attribute)\n",
    "    gain = 0\n",
    "    atr_index = list(enumerate(attribute))\n",
    "    \n",
    "    \n",
    "    for atr in s:\n",
    "        p_atr = attribute.count(atr) / len(attribute)\n",
    "        label_atr = []\n",
    "        for j in range(len(labels)):\n",
    "            if atr_index[j][1] == atr:\n",
    "                label_atr.append(labels[j])\n",
    "                \n",
    "        ent_atr = Ent(label_atr)\n",
    "        gain += p_atr*ent_atr\n",
    "    \n",
    "    return info_gain - gain\n",
    "\n",
    "def gain_rate(attribute, labels):\n",
    "    info_gain = Ent(labels)\n",
    "    s = set(attribute)\n",
    "    gain = 0\n",
    "    IV_atr = 0\n",
    "    atr_index = list(enumerate(attribute))\n",
    "    \n",
    "    \n",
    "    for atr in s:\n",
    "        p_atr = attribute.counts(atr) / len(attribute)\n",
    "        label_atr = []\n",
    "        for j in range(len(labels)):\n",
    "            if atr_index[j][1] == atr:\n",
    "                label_atr.append(labels[j])\n",
    "                \n",
    "        ent_atr = Ent(label_atr)\n",
    "        gain += p_atr*ent_atr\n",
    "        IV_atr += p_atr*np.log2(p_atr)\n",
    "    \n",
    "    gain_ratio = (info_gain - gain) / IV_atr\n",
    "    \n",
    "    return gain_ratio\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class TreeNode:\n",
    "    current_index = 0\n",
    "    def __init__(self, parent=None, attr_name=None, children=None, judge=None,  data_index=None,\n",
    "                 attr_value=None, rest_attribute=None):\n",
    "        \"\"\"\n",
    "        决策树结点类初始化方法\n",
    "        :param parent: 父节点\n",
    "        \"\"\"\n",
    "        self.parent = parent  \n",
    "        self.attribute_name = attr_name \n",
    "        self.attribute_value = attr_value  \n",
    "        self.children = children \n",
    "        self.judge = judge  \n",
    "        self.data_index = data_index  \n",
    "        self.index = TreeNode.current_index  \n",
    "        self.rest_attribute = rest_attribute  \n",
    "        TreeNode.current_index += 1\n",
    " \n",
    "    def to_string(self):\n",
    "        \"\"\"\n",
    "        用一个字符串来描述当前结点信息\n",
    "        一个普通结点的描述--------------------------------------------\n",
    "        current index : x;\n",
    "        parent index : xx;\n",
    "        parent node's attribute(父亲结点的属性划分（比方说色泽）)：青黑（此结点的色泽）\n",
    "        data：包含的训练数据\n",
    "        selected attribute(选择的属性)：xx\n",
    "        children(子节点)：x x x \n",
    "        \"\"\"\n",
    "        this_string = 'current index : ' + str(self.index) + \";\\n\"\n",
    "        if not (self.parent is None):\n",
    "            parent_node = self.parent\n",
    "            this_string = this_string + 'parent index : ' + str(parent_node.index) + \";\\n\"\n",
    "            this_string = this_string + str(parent_node.attribute_name) + \" : \" + str(self.attribute_value) + \";\\n\"\n",
    "        this_string = this_string + \"data : \" + str(self.data_index) + \";\\n\"\n",
    "        if not(self.children is None):\n",
    "            this_string = this_string + 'selected attribute is : ' + str(self.attribute_name) + \";\\n\"\n",
    "            child_list = []\n",
    "            for child in self.children:\n",
    "                child_list.append(child.index)\n",
    "            this_string = this_string + 'children : ' + str(child_list)\n",
    "        if not (self.judge is None):\n",
    "            this_string = this_string + 'label : ' + self.judge\n",
    "        return this_string\n",
    "    \n",
    "    \n",
    "\n",
    "def finish_node(current_node, X, label, split_type):\n",
    "    one_class = True\n",
    " \n",
    "    this_data_index = current_node.data_index\n",
    "    for i in this_data_index:\n",
    "        for j in this_data_index:\n",
    "            if label[i] != label[j]:\n",
    "                one_class = False\n",
    "                break\n",
    "        if not one_class:\n",
    "            break\n",
    "    if one_class:\n",
    "        \n",
    "        current_node.judge = label[this_data_index[0]]\n",
    "        return\n",
    "    \n",
    "    rest_title = current_node.rest_attribute \n",
    "    if len(rest_title) == 0: \n",
    "        label_count = {}\n",
    "        temp_data = current_node.data_index \n",
    "        for index in temp_data:\n",
    "            if label[index] in label_count:\n",
    "                label_count[label[index]] += 1\n",
    "            else:\n",
    "                label_count[label[index]] = 1\n",
    "        final_label = max(label_count)\n",
    "        current_node.judge = final_label\n",
    "        return\n",
    "    \n",
    "    \n",
    "    attribute_eva = {}  # 记录每个属性的评价(1.信息增益 2.增益率 3.基尼指数)\n",
    "    for attr in rest_title: #挑选属性\n",
    "        attr_values = []\n",
    "        current_label = []\n",
    "        for index in current_node.data_index:\n",
    "            this_data = X[index]\n",
    "            attr_values.append(this_data[attr]) \n",
    "            current_label.append(label[index])   \n",
    "        \n",
    "        \n",
    "        if attr not in ['密度', '含糖率']:\n",
    "            this_gain = split_selection(attr_values, current_label, split_type)  \n",
    "            attribute_eva[attr] = this_gain\n",
    "        else:\n",
    "            x_feature = sorted(set(attr_values)) \n",
    "            feature_values = []\n",
    "            for i in range(len(x_feature) - 1):  # 计算划分点\n",
    "                feature_values.append((float(x_feature[i]) + float(\n",
    "                    x_feature[i + 1])) / 2)\n",
    "\n",
    "            for threshold in feature_values:\n",
    "                attr_left = []\n",
    "                label_left = []\n",
    "                label_right = []\n",
    "                attr_right = []\n",
    "                min_entropy = 100\n",
    "                best_threshold = 0\n",
    "                for i in range(len(attr_values)):\n",
    "                    if attr_values[i] < threshold:\n",
    "                        attr_left.append(attr_values[i])\n",
    "                        label_left.append(current_label[i])\n",
    "                    else:\n",
    "                        attr_right.append(attr_values[i])\n",
    "                        label_right.append(current_label[i])\n",
    "                \n",
    "                prob_left = len(attr_left) / len(attr_values)\n",
    "                prob_right = len(attr_right) / len(attr_values)\n",
    "                entropy = prob_left * Ent(label_left) + prob_right * Ent(label_right)\n",
    "                \n",
    "                if entropy < min_entropy:\n",
    "                    min_entropy = entropy\n",
    "                    best_threshold = threshold\n",
    "                    \n",
    "            this_gain = Ent(current_label) - min_entropy\n",
    "            attribute_eva[attr] = this_gain\n",
    "            \n",
    "    print(attribute_eva)\n",
    "    best_attr = max(attribute_eva, key=attribute_eva.get)  \n",
    "    current_node.attribute_name = best_attr\n",
    "    rest_title.remove(best_attr)\n",
    " \n",
    "    \n",
    "\n",
    "    # 属性划分\n",
    "    best_titlevalue_dict = {}  # key是属性值的取值，value是个list记录所包含的样本序号\n",
    "    for index in current_node.data_index:\n",
    "        this_data = X[index] \n",
    "        if this_data[best_attr] in best_titlevalue_dict:\n",
    "            temp_list = best_titlevalue_dict[this_data[best_attr]]\n",
    "            temp_list.append(index)\n",
    "        else:                                \n",
    "            temp_list = [index]\n",
    "            best_titlevalue_dict[this_data[best_attr]] = temp_list\n",
    " \n",
    "    children_list = []\n",
    "    for key, index_list in best_titlevalue_dict.items():\n",
    "        a_child = TreeNode(parent=current_node, data_index=index_list, attr_value=key, rest_attribute=rest_title.copy())\n",
    "        children_list.append(a_child)\n",
    "    current_node.children = children_list\n",
    " \n",
    "   \n",
    "    for child in current_node.children:  \n",
    "        finish_node(child, X, label, split_type)\n",
    "\n",
    "def id3_tree(X, title, label, split_type):\n",
    "    n = len(X)\n",
    "    root_data = []\n",
    "    for i in range(0, n):\n",
    "        root_data.append(i)\n",
    "        \n",
    "    root_node = TreeNode(data_index=root_data, rest_attribute=title.copy())\n",
    "    finish_node(root_node, X, label, split_type)\n",
    "    \n",
    "    return root_node\n",
    " \n",
    "    \n",
    "def print_tree(root=TreeNode()):\n",
    "    \"\"\"\n",
    "    打印输出一颗树\n",
    "    :param root: 根节点\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    node_list = [root]\n",
    "    while(len(node_list)>0):\n",
    "        current_node = node_list[0]\n",
    "        print('--------------------------------------------')\n",
    "        print(current_node.to_string())\n",
    "        print('--------------------------------------------')\n",
    "        children_list = current_node.children\n",
    "        if not (children_list is None):\n",
    "            for child in children_list:\n",
    "                node_list.append(child)\n",
    "        node_list.remove(current_node)\n",
    "        \n",
    "        \n",
    "        \n",
    "data = [] \n",
    "label = []  \n",
    "for sample in wm_data:\n",
    "    a_dict = {}\n",
    "    dim = len(sample) - 1\n",
    "    for i in range(0, dim):\n",
    "        a_dict[Attributes[i]] = sample[i]\n",
    "    data.append(a_dict)\n",
    "    label.append(sample[dim])\n",
    "    \n",
    "    \n",
    "decision_tree = id3_tree(data, Attributes, label, 2)\n",
    "print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "86ed06a0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'清晰': [0, 1, 2, 3, 4, 5, 7, 9, 14], '稍糊': [6, 8, 12, 13, 16], '模糊': [10, 11, 15]}\n",
      "{'硬滑': [0, 1, 2, 3, 4, 7], '软粘': [5, 9, 14]}\n",
      "{0.403: [5], 0.243: [9], 0.36: [14]}\n",
      "{'软粘': [6], '硬滑': [8, 12, 13, 16]}\n",
      "--------------------------------------------\n",
      "current index : 1;\n",
      "data : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16];\n",
      "selected attribute is : 纹理;\n",
      "children : [2, 3, 4]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 2;\n",
      "parent index : 1;\n",
      "纹理 : 清晰;\n",
      "data : [0, 1, 2, 3, 4, 5, 7, 9, 14];\n",
      "selected attribute is : 触感;\n",
      "children : [5, 6]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 3;\n",
      "parent index : 1;\n",
      "纹理 : 稍糊;\n",
      "data : [6, 8, 12, 13, 16];\n",
      "selected attribute is : 触感;\n",
      "children : [10, 11]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 4;\n",
      "parent index : 1;\n",
      "纹理 : 模糊;\n",
      "data : [10, 11, 15];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 5;\n",
      "parent index : 2;\n",
      "触感 : 硬滑;\n",
      "data : [0, 1, 2, 3, 4, 7];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 6;\n",
      "parent index : 2;\n",
      "触感 : 软粘;\n",
      "data : [5, 9, 14];\n",
      "selected attribute is : 含糖率;\n",
      "children : [7, 8, 9]\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 10;\n",
      "parent index : 3;\n",
      "触感 : 软粘;\n",
      "data : [6];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 11;\n",
      "parent index : 3;\n",
      "触感 : 硬滑;\n",
      "data : [8, 12, 13, 16];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 7;\n",
      "parent index : 6;\n",
      "含糖率 : 0.403;\n",
      "data : [5];\n",
      "label : 是\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 8;\n",
      "parent index : 6;\n",
      "含糖率 : 0.243;\n",
      "data : [9];\n",
      "label : 否\n",
      "--------------------------------------------\n",
      "--------------------------------------------\n",
      "current index : 9;\n",
      "parent index : 6;\n",
      "含糖率 : 0.36;\n",
      "data : [14];\n",
      "label : 否\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "wm_data = pd.read_csv(r\"C:\\Users\\lenovo\\Desktop\\3.0.csv\")\n",
    "wm_data = wm_data.drop(['编号'], axis=1).values\n",
    "\n",
    "\n",
    "\n",
    "Attributes = ['色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '含糖率', '密度']\n",
    "\n",
    "\n",
    "def Gini(y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    freqs = counts / len(y)\n",
    "    \n",
    "    gini = 1 - np.sum(freqs**2)\n",
    "    \n",
    "    return gini\n",
    "\n",
    "\n",
    "def split_selection(attribute, y, split_type):\n",
    "    if split_type == 1:\n",
    "        return Gini(y)\n",
    "    \n",
    "    if split_type == 2:\n",
    "        return gain(attribute, y)\n",
    "        \n",
    "    if split_type == 3:\n",
    "        return gain_rate(attribute, y)\n",
    "    \n",
    "    \n",
    "def Ent(labels):\n",
    "    label_name = []\n",
    "    label_count = {}\n",
    "\n",
    "    for label in labels:\n",
    "        label_count[label] = label_count.get(label, 0) + 1\n",
    "        entropy = 0\n",
    "\n",
    "    for label in label_count:\n",
    "        prob = label_count[label] / len(labels)\n",
    "        entropy -= prob * np.log2(prob)\n",
    "        \n",
    "    return entropy\n",
    "\n",
    "def gain(attribute, labels):\n",
    "    info_gain = Ent(labels)\n",
    "    s = set(attribute)\n",
    "    gain = 0\n",
    "    atr_index = list(enumerate(attribute))\n",
    "    \n",
    "    \n",
    "    for atr in s:\n",
    "        p_atr = attribute.count(atr) / len(attribute)\n",
    "        label_atr = []\n",
    "        for j in range(len(labels)):\n",
    "            if atr_index[j][1] == atr:\n",
    "                label_atr.append(labels[j])\n",
    "                \n",
    "        ent_atr = Ent(label_atr)\n",
    "        gain += p_atr*ent_atr\n",
    "\n",
    "        \n",
    "    return info_gain - gain\n",
    "\n",
    "def gain_rate(attribute, labels):\n",
    "    info_gain = Ent(labels)\n",
    "    s = set(attribute)\n",
    "    gain = 0\n",
    "    IV_atr = 0\n",
    "    atr_index = list(enumerate(attribute))\n",
    "  \n",
    "    \n",
    "    for atr in s:\n",
    "        p_atr = attribute.count(atr) / len(attribute)\n",
    "        label_atr = []\n",
    "        for j in range(len(labels)):\n",
    "            if atr_index[j][1] == atr:\n",
    "                label_atr.append(labels[j])\n",
    "                \n",
    "        ent_atr = Ent(label_atr)\n",
    "        gain += p_atr*ent_atr\n",
    "        IV_atr -= p_atr*np.log2(p_atr)\n",
    "    \n",
    "    gain_ratio = (info_gain - gain) / IV_atr\n",
    "    \n",
    "    return gain_ratio\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "class TreeNode:\n",
    "    current_index = 0\n",
    "    def __init__(self, parent=None, attr_name=None, children=None, judge=None,  data_index=None,\n",
    "                 attr_value=None, rest_attribute=None):\n",
    "        \"\"\"\n",
    "        决策树结点类初始化方法\n",
    "        :param parent: 父节点\n",
    "        \"\"\"\n",
    "        self.parent = parent  \n",
    "        self.attribute_name = attr_name \n",
    "        self.attribute_value = attr_value  \n",
    "        self.children = children \n",
    "        self.judge = judge  \n",
    "        self.data_index = data_index  \n",
    "        self.index = TreeNode.current_index  \n",
    "        self.rest_attribute = rest_attribute  \n",
    "        TreeNode.current_index += 1\n",
    " \n",
    "    def to_string(self):\n",
    "        \"\"\"\n",
    "        用一个字符串来描述当前结点信息\n",
    "        一个普通结点的描述--------------------------------------------\n",
    "        current index : x;\n",
    "        parent index : xx;\n",
    "        parent node's attribute(父亲结点的属性划分（比方说色泽）)：青黑（此结点的色泽）\n",
    "        data：包含的训练数据\n",
    "        selected attribute(选择的属性)：xx\n",
    "        children(子节点)：x x x \n",
    "        \"\"\"\n",
    "        this_string = 'current index : ' + str(self.index) + \";\\n\"\n",
    "        if not (self.parent is None):\n",
    "            parent_node = self.parent\n",
    "            this_string = this_string + 'parent index : ' + str(parent_node.index) + \";\\n\"\n",
    "            this_string = this_string + str(parent_node.attribute_name) + \" : \" + str(self.attribute_value) + \";\\n\"\n",
    "        this_string = this_string + \"data : \" + str(self.data_index) + \";\\n\"\n",
    "        if not(self.children is None):\n",
    "            this_string = this_string + 'selected attribute is : ' + str(self.attribute_name) + \";\\n\"\n",
    "            child_list = []\n",
    "            for child in self.children:\n",
    "                child_list.append(child.index)\n",
    "            this_string = this_string + 'children : ' + str(child_list)\n",
    "        if not (self.judge is None):\n",
    "            this_string = this_string + 'label : ' + self.judge\n",
    "        return this_string\n",
    "    \n",
    "    \n",
    "\n",
    "def finish_node(current_node, X, label, split_type):\n",
    "    one_class = True\n",
    " \n",
    "    this_data_index = current_node.data_index\n",
    "    for i in this_data_index:\n",
    "        for j in this_data_index:\n",
    "            if label[i] != label[j]:\n",
    "                one_class = False\n",
    "                break\n",
    "        if not one_class:\n",
    "            break\n",
    "    if one_class:\n",
    "        \n",
    "        current_node.judge = label[this_data_index[0]]\n",
    "        return\n",
    "    \n",
    "    rest_title = current_node.rest_attribute \n",
    "    if len(rest_title) == 0: \n",
    "        label_count = {}\n",
    "        temp_data = current_node.data_index \n",
    "        for index in temp_data:\n",
    "            if label[index] in label_count:\n",
    "                label_count[label[index]] += 1\n",
    "            else:\n",
    "                label_count[label[index]] = 1\n",
    "        final_label = max(label_count)\n",
    "        current_node.judge = final_label\n",
    "        return\n",
    "    \n",
    "    \n",
    "    attribute_eva = {}  # 记录每个属性的评价(1.信息增益 2.增益率 3.基尼指数)\n",
    "    for attr in rest_title: #挑选属性\n",
    "        attr_values = []\n",
    "        current_label = []\n",
    "        for index in current_node.data_index:\n",
    "            this_data = X[index]\n",
    "            attr_values.append(this_data[attr]) \n",
    "            current_label.append(label[index])   \n",
    "        \n",
    "        \n",
    "        if attr not in ['密度', '含糖率']:\n",
    "            this_gain = split_selection(attr_values, current_label, split_type)  \n",
    "            attribute_eva[attr] = this_gain\n",
    "        else:\n",
    "            x_feature = sorted(set(attr_values)) \n",
    "            feature_values = []\n",
    "            for i in range(len(x_feature) - 1):  # 计算划分点\n",
    "                feature_values.append((float(x_feature[i]) + float(\n",
    "                    x_feature[i + 1])) / 2)\n",
    "\n",
    "            \n",
    "            for threshold in feature_values:\n",
    "                attr_left = []\n",
    "                label_left = []\n",
    "                label_right = []\n",
    "                attr_right = []\n",
    "                min_entropy = 100\n",
    "                best_threshold = 0\n",
    "                for i in range(len(attr_values)):\n",
    "                    if attr_values[i] < threshold:\n",
    "                        attr_left.append(attr_values[i])\n",
    "                        label_left.append(current_label[i])\n",
    "                    else:\n",
    "                        attr_right.append(attr_values[i])\n",
    "                        label_right.append(current_label[i])\n",
    "                \n",
    "                prob_left = len(attr_left) / len(attr_values)\n",
    "                prob_right = len(attr_right) / len(attr_values)\n",
    "                entropy = prob_left * Ent(label_left) + prob_right * Ent(label_right)\n",
    "                \n",
    "                if entropy < min_entropy:\n",
    "                    min_entropy = entropy\n",
    "                    best_threshold = threshold\n",
    "                    \n",
    "            this_gain = Ent(current_label) - min_entropy\n",
    "            attribute_eva[attr] = this_gain\n",
    "                \n",
    "\n",
    "    best_attr = max(attribute_eva, key=attribute_eva.get)  \n",
    "    current_node.attribute_name = best_attr\n",
    "    rest_title.remove(best_attr)\n",
    " \n",
    "    \n",
    "\n",
    "    # 属性划分\n",
    "    best_titlevalue_dict = {}  # key是属性值的取值，value是个list记录所包含的样本序号\n",
    "    for index in current_node.data_index:\n",
    "        this_data = X[index] \n",
    "        if this_data[best_attr] in best_titlevalue_dict:\n",
    "            temp_list = best_titlevalue_dict[this_data[best_attr]]\n",
    "            temp_list.append(index)\n",
    "        else:                                \n",
    "            temp_list = [index]\n",
    "            best_titlevalue_dict[this_data[best_attr]] = temp_list\n",
    " \n",
    "    print(best_titlevalue_dict)\n",
    "    children_list = []\n",
    "    for key, index_list in best_titlevalue_dict.items():\n",
    "        a_child = TreeNode(parent=current_node, data_index=index_list, attr_value=key, rest_attribute=rest_title.copy())\n",
    "        children_list.append(a_child)\n",
    "    current_node.children = children_list\n",
    " \n",
    "   \n",
    "    for child in current_node.children:  \n",
    "        finish_node(child, X, label, split_type)\n",
    "\n",
    "def id3_tree(X, title, label, split_type):\n",
    "    n = len(X)\n",
    "    root_data = []\n",
    "    for i in range(0, n):\n",
    "        root_data.append(i)\n",
    "        \n",
    "    root_node = TreeNode(data_index=root_data, rest_attribute=title.copy())\n",
    "    finish_node(root_node, X, label, split_type)\n",
    "    \n",
    "    return root_node\n",
    " \n",
    "    \n",
    "def print_tree(root=TreeNode()):\n",
    "    \"\"\"\n",
    "    打印输出一颗树\n",
    "    :param root: 根节点\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    node_list = [root]\n",
    "    while(len(node_list)>0):\n",
    "        current_node = node_list[0]\n",
    "        print('--------------------------------------------')\n",
    "        print(current_node.to_string())\n",
    "        print('--------------------------------------------')\n",
    "        children_list = current_node.children\n",
    "        if not (children_list is None):\n",
    "            for child in children_list:\n",
    "                node_list.append(child)\n",
    "        node_list.remove(current_node)\n",
    "        \n",
    "        \n",
    "        \n",
    "data = [] \n",
    "label = []  \n",
    "for sample in wm_data:\n",
    "    a_dict = {}\n",
    "    dim = len(sample) - 1\n",
    "    for i in range(0, dim):\n",
    "        a_dict[Attributes[i]] = sample[i]\n",
    "    data.append(a_dict)\n",
    "    label.append(sample[dim])\n",
    "    \n",
    "decision_tree = id3_tree(data, Attributes, label, 3)\n",
    "print_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3172da1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class TreeNode(object):\n",
    "    \n",
    "    def __init__(self, model=None, C=None, left=None, right=None):\n",
    "        self.model = model\n",
    "        self.C = C\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "def trainLinear(linear, x, y):\n",
    "    linear.fit(x, y)\n",
    "    return linear\n",
    "\n",
    "def binaryTrainSet(linear, x, y):\n",
    "    x0 = []\n",
    "    x1 = []\n",
    "    y0 = []\n",
    "    y1 = []\n",
    "    p = linear.predict(x)\n",
    "    for i in range(p.shape[0]):\n",
    "        if p[i] <= 0:\n",
    "            x0.append(x[i])\n",
    "            y0.append(y[i])\n",
    "        else:\n",
    "            x1.append(x[i])\n",
    "            y1.append(y[i])\n",
    "    return np.array(x0), np.array(x1), np.array(y0), np.array(y1)\n",
    "\n",
    "def score(linear, x, y):\n",
    "    #计算线性模型linear的精度\n",
    "    right = 0\n",
    "    p = linear.predict(x)\n",
    "    for i in range(p.shape[0]):\n",
    "        if p[i]<=0 and y[i]==-1 or p[i]>0 and y[i]==1:\n",
    "            right += 1\n",
    "    return right / x.shape[0]\n",
    "    \n",
    "def treeGenerate(root, x, y, precision):\n",
    "    root.model = LinearRegression()\n",
    "    root.model = trainLinear(root.model, x, y)\n",
    "    x0, x1, y0, y1 = binaryTrainSet(root.model, x, y)\n",
    "    \n",
    "    if len(x0)==0 or score(root.model, x0, y0)>= precision:\n",
    "        root.left = TreeNode(C=-1)\n",
    "    else:\n",
    "        root.left = TreeNode()\n",
    "        treeGenerate(root.left, x0, y0, precision)\n",
    "    \n",
    "    if len(x1)==0 or score(root.model, x1, y1) >= precision:\n",
    "        root.right = TreeNode(C=1)\n",
    "    else:\n",
    "        root.right = TreeNode()\n",
    "        treeGenerate(root.right, x1, y1, precision)\n",
    "\n",
    "def predict(root, xs):\n",
    "    if root.C is not None:\n",
    "        return root.C\n",
    "    else:\n",
    "        if root.model.predict(np.expand_dims(xs, axis=0)) <= 0:\n",
    "            return predict(root.left, xs)\n",
    "        else:\n",
    "            return predict(root.right, xs)\n",
    "\n",
    "def evaluate(root, x, y):\n",
    "    right = 0\n",
    "    for i in range(x.shape[0]):\n",
    "        if predict(root, x[i]) == y[i]:\n",
    "            right += 1\n",
    "    return right / x.shape[0]\n",
    "\n",
    "\n",
    "wm_data = pd.read_csv(r\"C:\\Users\\lenovo\\Desktop\\3.0.csv\")\n",
    "x = wm_data.drop(['编号', '色泽', '根蒂', '敲声', '纹理', '脐部', '触感', '好瓜'], axis=1).values\n",
    "wm_data['好瓜'] = wm_data['好瓜'].map({'是': 1, '否': 0})\n",
    "y = wm_data[\"好瓜\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=60090)\n",
    "y_train[y_train == 0] = -1\n",
    "y_test[y_test == 0] = -1\n",
    "root = TreeNode()\n",
    "treeGenerate(root, X_train, y_train, 0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e1121741",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集精度为: 1.0\n",
      "测试集精度为: 0.8333\n"
     ]
    }
   ],
   "source": [
    "scoreTrain = evaluate(root, X_train, y_train)\n",
    "scoreTest = evaluate(root, X_test, y_test)\n",
    "print('训练集精度为:', round(scoreTrain,4))\n",
    "print('测试集精度为:', round(scoreTest, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34be03b5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
